<!DOCTYPE html>
<!-- Authors: David Ouyang, Bryan He, Matt P. Lungren, Euan A. Ashley, David H. Liang, James Y. Zou 2019 -->
<html lang="en">
  <head>
    <title>EchoNet Dynamic</title>
    <meta name="description" content="EchoNet Dynamic: a Large New Cardiac Motion Video Data Resource for Medical Machine Learning." />
    <!--#include file="lagunita.html" -->
    <!--Lagunita Theme (TODO: Server side include)-->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    
    <script src="plugins/main.js?0"></script>
    
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
    <script src="lagunita/js/modernizr.custom.17475.js"></script>
    <script src="lagunita/js/bootstrap.min.js"></script>
    <script src="lagunita/js/base.js?v=1.0"></script>
    <script src="lagunita/js/custom.js"></script>
    <link rel="stylesheet" href="lagunita/css/bootstrap.min.css" type="text/css" />
    <link rel="stylesheet" href="//netdna.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" type="text/css" />
    <link rel="stylesheet" href="lagunita/css/base.min.css?v=0.1" type="text/css" />
    <link rel="stylesheet" href="lagunita/css/custom.css?v=0.1" type="text/css"/>
    <!--End Lagunita Theme-->

  </head>
  <body class="site-slogan">
    <!--#include file="header.html" -->
    <!--Header (TODO: Server side include)-->
    <div id="top">
      <div class="container">
        <!--=== Skip links ===-->
        <div id="skip"> <a href="#content" onClick="$('#content').focus()">Skip to content</a> </div>
        <!-- /Skip links -->
      </div>
    </div>
    <div id="brandbar">
      <div class="container"> <a href="http://www.stanford.edu"> <img src="lagunita/images/brandbar-stanford-logo%402x.png" alt="Stanford University" width="152" height="23"> </a> </div>
      <!-- .container end -->
    </div>
    <div id="header" class="clearfix" role="banner">
      <div class="container">
        <div class="row">
          <div class="col-md-8">
            <div id="logo" class=" clearfix"><a href="/"><img class="img-responsive" src="SU_Seal_Red.png" alt="Stanford University" /></a></div>
            <div id="signature">
              <div id="site-name"> <a href="/"><span id="site-name-1" style="font-size:40pt">EchoNet-Dynamic</span></a> </div>
              <div id="site-slogan"> <a href="/"><span id="site_slogan">A Large New Cardiac Motion Video Data Resource for Medical Machine Learning</span></a> </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- Menu -->
    <div id="mainmenu" class="clearfix" role="navigation">
      <div class="container">
        <div class="navbar navbar-default">
          <!-- main navigation -->
          <button type="button" class="navbar-toggle btn-navbar" data-toggle="collapse" data-target=".navbar-collapse"> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="menu-text">Menu</span></button>
          <!-- /nav-collapse -->
          <div class="navbar-collapse collapse">
            <div  role="navigation">
              <div id="primary-nav">
                <ul class="nav navbar-nav" aria-label="primary navigation">
                  <li id="nav-1"> <a href="index.html">Home</a> </li>
                  <li id="nav-1"> <a href="index.html#intro">Introduction</a> </li>
                  <li id="nav-1"> <a href="index.html#motivation">Motivation</a> </li>
                  <li id="nav-1"> <a href="index.html#dataset">Dataset</a> </li>
                  <li id="nav-1"> <a href="index.html#leaderboard">Leaderboard</a> </li>
                  <li id="nav-1"> <a href="index.html#access">Accessing Dataset</a> </li>
                </ul>
              </div>
            </div>
          </div>
          <!-- /nav-collapse -->
        </div>
        <!-- /navbar -->
      </div>
      <!-- /container -->
    </div>
    <!-- /mainmenu -->
    <!--End Header-->
    <div id="intro" class="container" role="introduction" tabindex="0">
      <h2>Introduction</h2>
      <h3>Echocardiography, or cardiac ultrasound, is the most widely used and readily available imaging technique to assess cardiac function and structure. Combining rapid image acquisition, high temporal resolution, and without the risks of ionizing radiation, echocardiography serves as the backbone of cardiovascular imaging and is one of the most frequently used imaging studies in the United States. For diseases ranging from cardiomyopathies to valvular heart diseases, echocardiography is both necessary and sufﬁcient to diagnose many cardiovascular diseases. We introduce a new large video dataset of echocardiograms for computer vision research. The EchoNet-Dynamic database includes 10,036 labeled echocardiogram videos and human expert tracing to provide images to study cardiac motion and chamber volumes. </h3>
      <br> 
      <br>
      <object data="Example1.avi" width="360" height="250"> <param name="src" value="Example1.avi" /> </object>
      <object data="Example2.avi" width="360" height="250"> <param name="src" value="Example2.avi" /> </object>
      </div>
      <h2 id="motivation">Motivation</h2>
      <h3> Machine learning analysis of biomedical images has seen significant recent advances. In contrast, there has been much less work on medical videos, despite the fact that videos are routinely used in many clinical settings. A major bottleneck for this is the the lack of openly available and well annotated medical video data. Computer vision has benefited greatly from many open databases which allow for collaboration, comparison, and creation of medical task specific architectures. We present the EchoNet-Dynamic Dataset of 10,036 echocardiography videos, spanning the range of typical echocardiography lab imaging conditions, with corresponding labeled measurements including ejection fraction, left ventricular volume at end-systole and end-diastole, and human expert tracings of the left ventricle as an aid in studying automated approaches to evaluate cardiac function. We additionally present the performance of three 3D convolutional architectures for video classification used to assess ejection fraction to near-expert human performance and as a benchmark for further collaboration, comparison, and creation of task-specific architectures.  To the best of our knowledge, this is the largest labeled medical video dataset made available publicly to researchers and medical professionals and first public report of video-based 3D convolutional architectures to assess cardiac function. </h3>
      

      <h2 id="dataset">Dataset</h2>
      <object data="Schematic.jpg" width="1280" height="480"> <param name="src" value="Schematic.jpg" /> </object>
        <li>
          <b>Echocardiogram Videos</b>:
A standard full resting echocardiogram study consists of a series of 50-100 videos and still images visualizing the heart from different angles, locations, and image acquisition techniques. The dataset contains 10,036 echocardiography videos from individuals who underwent echocardiography between 2006 and 2018 as part of routine clinical care at Stanford University Hospital. Each  video was cropped and masked to remove text, ECG and respirometer information, and other information outside of the scanning sector. The resulting square images were either 600x600 or 768x768 pixels depending on the ultrasound machine and downsampled by cubic interpolation using OpenCV into standardized 112x112 pixel videos. 
        </li>
    
            <li>
          <b>Measurements</b> In addition to the video itself, each study is linked to clinical measurements and calculations obtained by a registered sonographer and veriﬁed by a level 3 echocardiographer in the standard clinical workﬂow. A central metric of cardiac function is the left ventricular ejection fraction, which is used to diagnose cardiomyopathy, assess eligibility for certain chemotherapies, and determine indication for medical devices. The ejection fraction is expressed as a percentage and is the ratio of left ventricular end systolic volume (ESV) and left ventricular end diastolic volume (EDV) determined by (EDV - ESV) / EDV. 
              
          <img src="media/MetaDataVariables.JPG">
         </li>
    
        <li>
          <b>Tracings</b>:  In our dataset, and in standard echocardiography practice, the left ventricle is traced at the endocardial border at two separate time points representing end-systole and end-diastole for each video. Each tracing is used to estimate ventricular volume by integration of ventricular area over the length of the major axis of the ventricle
          
          <img src="media/TracingsFileVariables.JPG">
        </li>


      <h2 id="leaderboard">Leaderboard</h2> 
    
      To be coming in the future. For now, we present the model baseline.  
      <img src="media/ModelPerformance.JPG">
      
      <h2 id="access">Accessing Dataset</h2>    
          
          Please read the Stanford University School of Medicine EchoNet-Dynamic Research Use Agreement. Once you register to download the EchoNet-Dynamic dataset, you will receive a link to the download over email. Note that you may not share the link to download the dataset with others.
          
          
          
          Please read the Stanford University School of Medicine EchoNet-Dynamic Dataset Research Use Agreement. Once you register to download the MRNet dataset, you will receive a link to the download over email. Note that you may not share the link to download the dataset with others.</p><div class="well" id="agreement"><h3>Stanford University School of Medicine EchoNet-Dynamic Dataset Research Use Agreement</h3>
<p>By registering for downloads from the MRNet Dataset, you are agreeing to this Research Use Agreement, as well as to the Terms of Use of the Stanford University School of Medicine website as posted and updated periodically at http://www.stanford.edu/site/terms/.</p>
<p>1. Permission is granted to view and use the EchoNet-Dynamic Dataset without charge for personal, non-commercial research purposes only. Any commercial use, sale, or other monetization is prohibited.</p>
<p>2. Other than the rights granted herein, the Stanford University School of Medicine (&ldquo;School of Medicine&rdquo;) retains all rights, title, and interest in the EchoNet-Dynamic Dataset.</p>
<p>3. You may make a verbatim copy of the EchoNet-Dynamic Dataset for personal, non-commercial research use as permitted in this Research Use Agreement. If another user within your organization wishes to use the EchoNet-Dynamic Dataset, they must register as an individual user and comply with all the terms of this Research Use Agreement.</p>
<p>4. YOU MAY NOT DISTRIBUTE, PUBLISH, OR REPRODUCE A COPY of any portion or all of the MRNet Dataset to others without specific prior written permission from the School of Medicine.</p>
<p>5. YOU MAY NOT SHARE THE DOWNLOAD LINK to the MRNet dataset to others. If another user within your organization wishes to use the EchoNet-Dynamic Dataset, they must register as an individual user and comply with all the terms of this Research Use Agreement.</p>
<p>6. You must not modify, reverse engineer, decompile, or create derivative works from the EchoNet-Dynamic Dataset. You must not remove or alter any copyright or other proprietary notices in the EchoNet-Dynamic Dataset.</p>
<p>7. The EchoNet-Dynamic Dataset has not been reviewed or approved by the Food and Drug Administration, and is for non-clinical, Research Use Only. In no event shall data or images generated through the use of the EchoNet-Dynamic Dataset be used or relied upon in the diagnosis or provision of patient care.</p>
<p>8. THE ECHONET-DYNAMIC DATASET IS PROVIDED "AS IS," AND STANFORD UNIVERSITY AND ITS COLLABORATORS DO NOT MAKE ANY WARRANTY, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE, NOR DO THEY ASSUME ANY LIABILITY OR RESPONSIBILITY FOR THE USE OF THIS MRNet DATASET.</p>
<p>9. You will not make any attempt to re-identify any of the individual data subjects. Re-identification of individuals is strictly prohibited. Any re-identification of any individual data subject shall be immediately reported to the School of Medicine.</p>
<p>10. Any violation of this Research Use Agreement or other impermissible use shall be grounds for immediate termination of use of this EchoNet-Dynamic Dataset. In the event that the School of Medicine determines that the recipient has violated this Research Use Agreement or other impermissible use has been made, the School of Medicine may direct that the undersigned data recipient immediately return all copies of the EchoNet-Dynamic Dataset and retain no copies thereof even if you did not cause the violation or impermissible use.</p>
<p>In consideration for your agreement to the terms and conditions contained here, Stanford grants you permission to view and use the MRNet Dataset for personal, non-commercial research. You may not otherwise copy, reproduce, retransmit, distribute, publish, commercially exploit or otherwise transfer any material.</p>
<h4>Limitation of Use</h4>
<p>You may use EchoNet-Dynamic Dataset for legal purposes only.</p>
<p>You agree to indemnify and hold Stanford harmless from any claims, losses or damages, including legal fees, arising out of or resulting from your use of the MRNet Dataset or your violation or role in violation of these Terms. You agree to fully cooperate in Stanford&rsquo;s defense against any such claims. These Terms shall be governed by and interpreted in accordance with the laws of California. </p></div><!-- Begin MailChimp Signup Form -->
          
  </body>
</html>
